\chapter{June 25, 2024}

\section{Vector Functions Continued}

Just as differentiation is defined on vector functions, integration is also defined.

\begin{proposition}
    For a vector function $\vec{r}(t) = \left<f(t), g(t), h(t)\right>$,
    \[\int \vec{r}(t)dt = \left<\int f(t)dt, \int g(t)dt, \int h(t)dt\right>.\]
\end{proposition}

Namely, $\int \vec{r}(t)dt = \vec{R}(t)$ just as $\int f(t)dt = F(t)$ for any general scalar function $f$. The above definition also applies for definite integrals.

\begin{proposition}
    For a vector function $\vec{r}(t) = \left<f(t), g(t), h(t)\right>$,
    \[\int_{a}^{b} \vec{r}(t)dt = \left<F(t) \biggr\vert_{a}^{b}, G(t) \biggr\vert_{a}^{b}, H(t) \biggr\vert_{a}^{b}\right>.\]
\end{proposition}

With integrals defined for vector functions, we can begin to evaluate different applications such as arclength.

\begin{theorem}
    Given a vector function $\vec{r}(t) = \left<f(t), g(t), h(t)\right>$ and two inputs $t_{1}$, $t_{2} \in D_{\vec{r}}$, the length of the curve between $\vec{r}(t_{1})$ and $\vec{r}(t_{2})$ is given by the formula
    \[L = \int_{t_{1}}^{t_{2}} \sqrt{\left[f'(t)\right]^{2} + \left[g'(t)\right]^{2} + \left[h'(t)\right]^{2}}dt.\]
\end{theorem}

\begin{proof}
    Consider an infinitesimally small step of length $\epsilon$ in the input $t$. We have that
    \begin{align*}
        L &= \magnitude{\vec{r}(t + \epsilon) - \vec{r}(t)} \\
        &= \sqrt{\left[f(t + \epsilon) - f(t)\right]^{2} + \left[g(t + \epsilon) - g(t)\right]^{2} + \left[h(t + \epsilon) - h(t)\right]^{2}} \\
        &= \sqrt{\left[\frac{f(t + \epsilon) - f(t)}{\epsilon}\right]^{2} + \left[\frac{g(t + \epsilon) - g(t)}{\epsilon}\right]^{2} + \left[\frac{h(t + \epsilon) - h(t)}{\epsilon}\right]^{2}} \cdot \epsilon \\
        &= \sqrt{\left[f'(t)\right]^{2} + \left[g'(t)\right]^{2} + \left[h'(t)\right]^{2}}dt.
    \end{align*}
    Now, the length over a longer period is just an infinite sum, or integral, of the previous which completes the proof.
\end{proof}

\begin{remark}
    The jump to the last step is made from the definition of a derivative from earlier courses that states
    \[f'(t) = \lim_{\epsilon \to 0} \frac{f(t + \epsilon) - f(t)}{\epsilon}\]
    and the assumption that $\epsilon$ approches zero as stated at the front end of the proof.
\end{remark}

Like simpler functions explored in earlier calculus classes, the derivative itself does not explain the entirety of a curve`s path. Rather, it just tells us the direction. Aspects including how the path curves or even twists rely on more exploration.

\begin{proposition}
    The curvature $\kappa$ of a vector function $\vec{r}(t)$ is defined by
    \[\kappa(t) = \frac{\magnitude{\ddvec{T}(t)}}{\magnitude{\ddvec{r}(t)}}.\]
\end{proposition}

As you may notice, the above is a scalar. If we want the direction, we must consider the normal unit vector of the path, $\vec{N}(t)$.

\begin{proposition}
    The normal unit vector $\vec{N}(t)$ to $\vec{r}(t)$ is defined by
    \[\vec{N}(t) = \frac{\ddvec{T}(t)}{\magnitude{\ddvec{T}(t)}}.\]
\end{proposition}

This vector is always perpendicular to $\vec{T}(t)$ and points in the direction of curvature. With the inclusion of one more vector, the binormal unit vector, we complete a reference frame called the Frenet frame that describes the behavior of a vector function in space.

\begin{proposition}
    The binormal unit vector $\vec{B}(t)$ of $\vec{r}(t)$ is defined by
    \[\vec{B}(t) = \vec{T}(t) \times \vec{N}(t).\]
\end{proposition}

So far, most of the motion that has been described is similar to a three-dimensional application of derivatives and second derivatives, but the concept of torsion, or twisting, also arises.

\begin{proposition}
    The torsion $\tau(t)$ of $\vec{r}(t)$ is defined by
    \[\tau(t) = -\vec{N}(t) \cdot \ddvec{B}(t).\]
\end{proposition}